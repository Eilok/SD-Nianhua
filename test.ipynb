{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 11.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "from peft import PeftConfig, PeftModel, set_peft_model_state_dict\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "lora_path = \"./post_model/AdaLora/epoch10\"\n",
    "control_path = \"../autodl-tmp/models--lllyasviel--control_v11p_sd15_canny/snapshots/115a470d547982438f70198e353a921996e2e819\"\n",
    "SD_path = \"../autodl-tmp/runwayml--stable-diffusion/snapshots/f03de327dd89b501a01da37fc5240cf4fdba85a1\"\n",
    "\n",
    "# 加载 ControlNet 和 Stable Diffusion\n",
    "controlnet = ControlNetModel.from_pretrained(control_path)\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    SD_path, controlnet=controlnet\n",
    ").to(\"cuda\")\n",
    "# pipe.load_lora_weights(lora_path)\n",
    "fine_model = PeftModel.from_pretrained(pipe.unet, lora_path)\n",
    "set_peft_model_state_dict(pipe.unet, fine_model.state_dict())\n",
    "pipe.unet = fine_model.model\n",
    "pipe.safety_checker = None  # 禁用安全检查器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:11<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image saved to: ./AdaLoRA_img/generated_human_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [01:16<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image saved to: ./AdaLoRA_img/generated_human_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:06<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image saved to: ./AdaLoRA_img/generated_human_3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:06<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image saved to: ./AdaLoRA_img/generated_human_4.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:45<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image saved to: ./AdaLoRA_img/generated_human_5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [01:07<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated image saved to: ./AdaLoRA_img/generated_human_6.jpg\n",
      "Processing complete. All images have been generated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 输入文件夹和输出文件夹路径\n",
    "input_folder = \"./human\"\n",
    "output_folder = \"./generated_images/AdaLoRA_img\"\n",
    "\n",
    "# 创建输出文件夹（如果不存在）\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 遍历 human 文件夹下的所有图片\n",
    "for filename in os.listdir(input_folder):\n",
    "    # 确保只处理图片文件\n",
    "    if filename.endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, f\"generated_{filename}\")\n",
    "\n",
    "        # 加载并预处理输入图像\n",
    "        input_image = cv2.imread(input_path)\n",
    "        gray = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, threshold1=100, threshold2=200)\n",
    "        edges_image = Image.fromarray(edges)\n",
    "\n",
    "        # 生成年画风格的图像\n",
    "        prompt = \"a traditional Chinese New Year painting style of a warrior figure, vibrant colors, detailed lines\"\n",
    "        generated_image = pipe(\n",
    "            prompt, \n",
    "            image=edges_image, \n",
    "            num_inference_steps=120\n",
    "        ).images[0]\n",
    "\n",
    "        # 保存生成结果\n",
    "        generated_image.save(output_path)\n",
    "        print(f\"Generated image saved to: {output_path}\")\n",
    "\n",
    "print(\"Processing complete. All images have been generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
